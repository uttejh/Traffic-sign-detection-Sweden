{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training and testing data from csv files\n",
    "train_dataframe = pd.read_csv('../train.csv')\n",
    "test_dataframe = pd.read_csv('../test.csv')\n",
    "\n",
    "# Get all unique labels\n",
    "labels = train_dataframe.label.unique()\n",
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# Read a base model which is pretrained on imagenet\n",
    "base_model = ResNet50(include_top=False, pooling='avg', weights='imagenet',input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image data\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=train_dataframe, directory=\"../data/\", x_col=\"file_name\", y_col=\"label\", class_mode=\"categorical\", target_size=(32,32), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "# function build a model\n",
    "def finetune_model(base_model, dropout, fc_layers, num_classes):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    # Flatten the layer to form FC layer\n",
    "    x = Flatten()(x)\n",
    "    for fc in fc_layers:\n",
    "        # create an FC layer to generate dropouts\n",
    "        x = Dense(fc, activation='relu')(x) \n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "    # Ouput layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x) \n",
    "    \n",
    "    # Final model\n",
    "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return finetune_model\n",
    "\n",
    "# fully connected layer neurons\n",
    "fc_Layers = [1024, 1024]\n",
    "\n",
    "#dropout percentage\n",
    "dropout = 0.5\n",
    "\n",
    "# build a finetune model\n",
    "finetune_model = finetune_model(base_model, \n",
    "                                      dropout=dropout, \n",
    "                                      fc_layers=fc_Layers, \n",
    "                                      num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "num_train_images = 2503\n",
    "\n",
    "# Compile the model with a learning rate and metrics\n",
    "finetune_model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# path to save training weights\n",
    "filepath=\"ResNet50_model_one_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# start training\n",
    "history = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n",
    "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
    "                                       shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a loss graph\n",
    "def loss_graph(data):\n",
    "    acc = data.history['acc']\n",
    "    loss = data.history['loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, loss, 'r')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.show()\n",
    "\n",
    "loss_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "from keras.models import load_model\n",
    "model = load_model('ResNet50_model_one_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_array = []\n",
    "train_labels = []\n",
    "numb=1\n",
    "\n",
    "# Data Augmentation\n",
    "for imgpath,label in zip(train_dataframe.file_name, train_dataframe.label):\n",
    "    \n",
    "    # read image\n",
    "    img = Image.open(\"/home/eteamcon/Downloads/sweden-traffic-signs-classification-eng/data/\"+imgpath)\n",
    "    \n",
    "    # resize image\n",
    "    img = (img.resize((224,224), Image.ANTIALIAS))\n",
    "    \n",
    "    # convert image to pixels\n",
    "    temp1 = np.asarray(img)/255\n",
    "    \n",
    "    \n",
    "    # flip images according to the label\n",
    "    if label == \"PEDESTRIAN_CROSSING\" or label == \"PASS_EITHER_SIDE\" or label == \"GIVE_WAY\":\n",
    "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        temp2 = np.asarray(img).astype(np.float32)/255\n",
    "        train_image_array.append(temp2)\n",
    "        train_labels.append(label)\n",
    "    elif label == \"PRIORITY_ROAD\" or label == \"NO_STOPPING_NO_STANDING\":\n",
    "        img = img.rotate(90)\n",
    "        temp2 = np.asarray(img).astype(np.float32)/255\n",
    "        train_image_array.append(temp2)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "        img = img.rotate(180)\n",
    "        temp2 = np.asarray(img).astype(np.float32)/255\n",
    "        train_image_array.append(temp2)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "        img = img.rotate(270)\n",
    "        temp2 = np.asarray(img).astype(np.float32)/255\n",
    "        train_image_array.append(temp2)\n",
    "        train_labels.append(label)\n",
    "    elif label == \"30_SIGN\" or label == \"100_SIGN\" or label == \"110_SIGN\":\n",
    "        img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        temp2 = np.asarray(img).astype(np.float32)/255\n",
    "        train_image_array.append(temp2)\n",
    "       \n",
    "        train_labels.append(label)\n",
    "    elif label == \"NO_PARKING\":\n",
    "        temp_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        img = temp_img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        temp2 = np.asarray(img).astype(np.float32)/255\n",
    "        train_image_array.append(temp2)\n",
    "        train_labels.append(label)\n",
    "    \n",
    "\n",
    "print \"The shape of the new training dataset after Augmentation is \"+ str(np.shape(train_image_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding labels to train again on augmented data\n",
    "encoded_labels = pd.get_dummies(train_labels)\n",
    "encoded_labels.T.reindex(np.sort(labels)).T.fillna(0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"ResNet50_augmented_model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# start training on augmented data\n",
    "model.fit(np.array(train_image_array), (encoded_labels),  batch_size=32, epochs=50, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# predict class labels on test dataset\n",
    "class_list = np.sort(labels)\n",
    "ans=[]\n",
    "for i in range(len(test_dataframe.file_name)):\n",
    "    test_image = image.load_img(\"/home/eteamcon/Downloads/sweden-traffic-signs-classification-eng/data/\"+test_dataframe.file_name[i], target_size = (224, 224)) \n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image/255, axis = 0)\n",
    "\n",
    "    val=model.predict(test_image)\n",
    "    ind = np.argmax(val[0])\n",
    "\n",
    "    ans.append(class_list[ind])\n",
    "    print i\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write prediction to a csv file\n",
    "test_dataframe = test_dataframe.assign(label=ans)\n",
    "test_dataframe.to_csv(\"answers.csv\", sep=',', index=False)\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on a single image\n",
    "\n",
    "To validate the model: run the following blocks seperately\n",
    "The following blocks will allow the user to load the trained model and display predictions on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "model = load_model('ResNet50_augmented_model.h5')\n",
    "from keras.preprocessing import image\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "train_dataframe = pd.read_csv('train.csv')\n",
    "test_dataframe = pd.read_csv('test.csv')\n",
    "\n",
    "# Get all unique labels\n",
    "labels = train_dataframe.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefe8cbb550>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class label is: 110_SIGN\n"
     ]
    }
   ],
   "source": [
    "# choose image (i = 0 or 1 or ... 9)\n",
    "i=0\n",
    "\n",
    "test_image = image.load_img(\"data/\"+test_dataframe.file_name[i], target_size = (224, 224)) \n",
    "\n",
    "# display the image\n",
    "plt.figure()\n",
    "plt.imshow(test_image) \n",
    "plt.show()\n",
    "\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image/255, axis = 0)\n",
    "\n",
    "val=model.predict(test_image)\n",
    "ind = np.argmax(val[0])\n",
    "lab = np.sort(labels)[ind]\n",
    "print(\"The predicted class label is: \" + str(lab))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
